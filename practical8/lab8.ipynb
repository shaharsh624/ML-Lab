{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectKBest:\n",
    "    def __init__(self, score_func, k='all'):\n",
    "        self.score_func = score_func\n",
    "        self.k = k\n",
    "        self.scores_ = None\n",
    "        self.selected_features_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y = y.ravel()\n",
    "        self.scores_ = np.array([self.score_func(X.iloc[:, i], y) for i in range(X.shape[1])])\n",
    "\n",
    "        if self.k == 'all':\n",
    "            self.k = X.shape[1]\n",
    "\n",
    "        self.selected_indices_ = np.argsort(self.scores_)[-self.k:]\n",
    "        self.selected_features_ = X.columns[self.selected_indices_]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.iloc[:, self.selected_indices_]\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.fit(X, y).transform(X)\n",
    "\n",
    "def chi2_score(x, y):\n",
    "    contingency_table = pd.crosstab(x, y)\n",
    "    chi2_stat, _, _, _ = chi2_contingency(contingency_table)\n",
    "    return chi2_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils import check_X_y, check_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFE:\n",
    "    def __init__(self, estimator, n_features_to_select=1):\n",
    "        self.estimator = estimator\n",
    "        self.n_features_to_select = n_features_to_select\n",
    "        self.support_ = None\n",
    "        self.ranking_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        n_features = X.shape[1]\n",
    "        self.ranking_ = np.zeros(n_features)\n",
    "\n",
    "        while n_features > self.n_features_to_select:\n",
    "            self.estimator.fit(X, y)\n",
    "            importances = self.estimator.feature_importances_ if hasattr(self.estimator, 'feature_importances_') else np.abs(self.estimator.coef_)\n",
    "            worst_feature = np.argmin(importances)\n",
    "\n",
    "            self.ranking_[worst_feature] += 1\n",
    "            X = np.delete(X, worst_feature, axis=1)\n",
    "            n_features -= 1\n",
    "\n",
    "        self.support_ = np.where(self.ranking_ == 0)[0]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.iloc[:, self.support_]\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.utils import check_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1FeatureSelector:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        self.model = Lasso(alpha=self.alpha)\n",
    "        self.selected_features_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.model.fit(X, y)\n",
    "        self.selected_features_ = np.where(self.model.coef_ != 0)[0]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.iloc[:, self.selected_features_]\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import check_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeBasedFeatureSelector:\n",
    "    def __init__(self, n_estimators=100):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.model = RandomForestClassifier(n_estimators=self.n_estimators)\n",
    "        self.selected_features_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.model.fit(X, y)\n",
    "        importances = self.model.feature_importances_\n",
    "        self.selected_features_ = np.where(importances > 0)[0]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.iloc[:, self.selected_features_]\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (KBest): Index(['petal width (cm)', 'petal length (cm)'], dtype='object')\n",
      "Selected Features (RFE): Index(['petal length (cm)', 'petal width (cm)'], dtype='object')\n",
      "Selected Features (L1): Index(['petal length (cm)'], dtype='object')\n",
      "Selected Features (Tree-Based): Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
      "       'petal width (cm)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Sample Data\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "# Univariate Feature Selection\n",
    "selector_kbest = SelectKBest(score_func=chi2_score, k=2)\n",
    "X_kbest = selector_kbest.fit_transform(X, y)\n",
    "print(\"Selected Features (KBest):\", selector_kbest.selected_features_)\n",
    "\n",
    "# Recursive Feature Elimination\n",
    "rfe_selector = RFE(estimator=RandomForestClassifier(), n_features_to_select=2)\n",
    "X_rfe = rfe_selector.fit_transform(X, y)\n",
    "print(\"Selected Features (RFE):\", X.columns[rfe_selector.support_])\n",
    "\n",
    "# L1-Based Feature Selection\n",
    "l1_selector = L1FeatureSelector(alpha=0.1)\n",
    "X_l1 = l1_selector.fit_transform(X, y)\n",
    "print(\"Selected Features (L1):\", X.columns[l1_selector.selected_features_])\n",
    "\n",
    "# Tree-Based Feature Selection\n",
    "tree_selector = TreeBasedFeatureSelector()\n",
    "X_tree = tree_selector.fit_transform(X, y)\n",
    "print(\"Selected Features (Tree-Based):\", X.columns[tree_selector.selected_features_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
